backprop: true
backpropType: "Standard"
cacheMode: "NONE"
confs:
- cacheMode: "NONE"
  epochCount: 0
  iterationCount: 0
  l1ByParam: {}
  l2ByParam: {}
  layer: !<org.deeplearning4j.nn.conf.layers.DenseLayer>
    activationFn: !<org.nd4j.linalg.activations.impl.ActivationTanH> {}
    biasInit: 0.0
    biasUpdater: null
    constraints: null
    dist: null
    gradientNormalization: "None"
    gradientNormalizationThreshold: 1.0
    hasBias: true
    idropout: null
    iupdater: !<org.nd4j.linalg.learning.config.Nesterovs>
      learningRate: 0.1
      momentum: 0.9
    l1: 0.0
    l1Bias: 0.0
    l2: 1.0E-4
    l2Bias: 0.0
    layerName: "layer0"
    nin: 80
    nout: 10
    weightInit: "XAVIER"
    weightNoise: null
  maxNumLineSearchIterations: 5
  miniBatch: true
  minimize: true
  optimizationAlgo: "CONJUGATE_GRADIENT"
  pretrain: false
  seed: 1533201904635
  stepFunction: null
  variables: []
- cacheMode: "NONE"
  epochCount: 0
  iterationCount: 0
  l1ByParam: {}
  l2ByParam: {}
  layer: !<org.deeplearning4j.nn.conf.layers.DenseLayer>
    activationFn: !<org.nd4j.linalg.activations.impl.ActivationTanH> {}
    biasInit: 0.0
    biasUpdater: null
    constraints: null
    dist: null
    gradientNormalization: "None"
    gradientNormalizationThreshold: 1.0
    hasBias: true
    idropout: null
    iupdater: !<org.nd4j.linalg.learning.config.Nesterovs>
      learningRate: 0.1
      momentum: 0.9
    l1: 0.0
    l1Bias: 0.0
    l2: 1.0E-4
    l2Bias: 0.0
    layerName: "layer1"
    nin: 10
    nout: 10
    weightInit: "XAVIER"
    weightNoise: null
  maxNumLineSearchIterations: 5
  miniBatch: true
  minimize: true
  optimizationAlgo: "CONJUGATE_GRADIENT"
  pretrain: false
  seed: 1533201904635
  stepFunction: null
  variables: []
- cacheMode: "NONE"
  epochCount: 0
  iterationCount: 0
  l1ByParam: {}
  l2ByParam: {}
  layer: !<org.deeplearning4j.nn.conf.layers.DenseLayer>
    activationFn: !<org.nd4j.linalg.activations.impl.ActivationTanH> {}
    biasInit: 0.0
    biasUpdater: null
    constraints: null
    dist: null
    gradientNormalization: "None"
    gradientNormalizationThreshold: 1.0
    hasBias: true
    idropout: null
    iupdater: !<org.nd4j.linalg.learning.config.Nesterovs>
      learningRate: 0.1
      momentum: 0.9
    l1: 0.0
    l1Bias: 0.0
    l2: 1.0E-4
    l2Bias: 0.0
    layerName: "layer2"
    nin: 10
    nout: 10
    weightInit: "XAVIER"
    weightNoise: null
  maxNumLineSearchIterations: 5
  miniBatch: true
  minimize: true
  optimizationAlgo: "CONJUGATE_GRADIENT"
  pretrain: false
  seed: 1533201904635
  stepFunction: null
  variables: []
- cacheMode: "NONE"
  epochCount: 0
  iterationCount: 0
  l1ByParam: {}
  l2ByParam: {}
  layer: !<org.deeplearning4j.nn.conf.layers.DenseLayer>
    activationFn: !<org.nd4j.linalg.activations.impl.ActivationTanH> {}
    biasInit: 0.0
    biasUpdater: null
    constraints: null
    dist: null
    gradientNormalization: "None"
    gradientNormalizationThreshold: 1.0
    hasBias: true
    idropout: null
    iupdater: !<org.nd4j.linalg.learning.config.Nesterovs>
      learningRate: 0.1
      momentum: 0.9
    l1: 0.0
    l1Bias: 0.0
    l2: 1.0E-4
    l2Bias: 0.0
    layerName: "layer3"
    nin: 10
    nout: 10
    weightInit: "XAVIER"
    weightNoise: null
  maxNumLineSearchIterations: 5
  miniBatch: true
  minimize: true
  optimizationAlgo: "CONJUGATE_GRADIENT"
  pretrain: false
  seed: 1533201904635
  stepFunction: null
  variables: []
- cacheMode: "NONE"
  epochCount: 0
  iterationCount: 0
  l1ByParam: {}
  l2ByParam: {}
  layer: !<org.deeplearning4j.nn.conf.layers.DenseLayer>
    activationFn: !<org.nd4j.linalg.activations.impl.ActivationTanH> {}
    biasInit: 0.0
    biasUpdater: null
    constraints: null
    dist: null
    gradientNormalization: "None"
    gradientNormalizationThreshold: 1.0
    hasBias: true
    idropout: null
    iupdater: !<org.nd4j.linalg.learning.config.Nesterovs>
      learningRate: 0.1
      momentum: 0.9
    l1: 0.0
    l1Bias: 0.0
    l2: 1.0E-4
    l2Bias: 0.0
    layerName: "layer4"
    nin: 10
    nout: 10
    weightInit: "XAVIER"
    weightNoise: null
  maxNumLineSearchIterations: 5
  miniBatch: true
  minimize: true
  optimizationAlgo: "CONJUGATE_GRADIENT"
  pretrain: false
  seed: 1533201904635
  stepFunction: null
  variables: []
- cacheMode: "NONE"
  epochCount: 0
  iterationCount: 0
  l1ByParam: {}
  l2ByParam: {}
  layer: !<org.deeplearning4j.nn.conf.layers.OutputLayer>
    activationFn: !<org.nd4j.linalg.activations.impl.ActivationSoftmax> {}
    biasInit: 0.0
    biasUpdater: null
    constraints: null
    dist: null
    gradientNormalization: "None"
    gradientNormalizationThreshold: 1.0
    hasBias: true
    idropout: null
    iupdater: !<org.nd4j.linalg.learning.config.Nesterovs>
      learningRate: 0.1
      momentum: 0.9
    l1: 0.0
    l1Bias: 0.0
    l2: 1.0E-4
    l2Bias: 0.0
    layerName: "layer5"
    lossFn: !<org.nd4j.linalg.lossfunctions.impl.LossBinaryXENT>
      clipEps: 1.0E-5
      configProperties: false
    nin: 10
    nout: 2
    weightInit: "XAVIER"
    weightNoise: null
  maxNumLineSearchIterations: 5
  miniBatch: true
  minimize: true
  optimizationAlgo: "CONJUGATE_GRADIENT"
  pretrain: false
  seed: 1533201904635
  stepFunction: null
  variables: []
epochCount: 0
inferenceWorkspaceMode: "ENABLED"
inputPreProcessors: {}
iterationCount: 0
pretrain: false
tbpttBackLength: 20
tbpttFwdLength: 20
trainingWorkspaceMode: "ENABLED"
